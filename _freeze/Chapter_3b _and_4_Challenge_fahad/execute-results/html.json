{
  "hash": "c5b9eb3ac1cd827ee19dcc587c4c6b9f",
  "result": {
    "markdown": "---\ntitle: \"Challenge 3 (II) & 4 combined Automated Machine Learning and Performance Measures\"\ndate: \"2024-06-20\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    df_print: paged\n    collapsed: false\n    number_sections: true\n    toc_depth: 3\n    #code_folding: hide\n---\n\n\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-1_03d2d8585846bf60beb06f215939913b'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(GGally)\nlibrary(h2o)\nlibrary(recipes)\nlibrary(rsample)\n```\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-2_139aa3738815cd8d134e87272d55376f'}\n\n```{.r .cell-code}\nproduct_backorders_tbl <- read_csv(\"C:/Users/Lenovo/OneDrive/Desktop/daqtascience/ss24-bdml-Fahad221999/Business Decisions with Machine Learning/product_backorders.txt\")\nglimpse(product_backorders_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 19,053\nColumns: 23\n$ sku               <dbl> 1113121, 1113268, 1113874, 1114222, 1114823, 1115453…\n$ national_inv      <dbl> 0, 0, 20, 0, 0, 55, -34, 4, 2, -7, 1, 2, 0, 0, 0, 0,…\n$ lead_time         <dbl> 8, 8, 2, 8, 12, 8, 8, 9, 8, 8, 8, 8, 12, 2, 12, 4, 2…\n$ in_transit_qty    <dbl> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0…\n$ forecast_3_month  <dbl> 6, 2, 45, 9, 31, 216, 120, 43, 4, 56, 2, 5, 5, 54, 4…\n$ forecast_6_month  <dbl> 6, 3, 99, 14, 31, 360, 240, 67, 6, 96, 4, 9, 6, 72, …\n$ forecast_9_month  <dbl> 6, 4, 153, 21, 31, 492, 240, 115, 9, 112, 6, 13, 9, …\n$ sales_1_month     <dbl> 0, 1, 16, 5, 7, 30, 83, 5, 1, 13, 0, 1, 0, 0, 1, 0, …\n$ sales_3_month     <dbl> 4, 2, 42, 17, 15, 108, 122, 22, 5, 30, 2, 5, 4, 0, 3…\n$ sales_6_month     <dbl> 9, 3, 80, 36, 33, 275, 144, 40, 6, 56, 3, 8, 5, 0, 4…\n$ sales_9_month     <dbl> 12, 3, 111, 43, 47, 340, 165, 58, 9, 76, 4, 11, 6, 0…\n$ min_bank          <dbl> 0, 0, 10, 0, 2, 51, 33, 4, 2, 0, 0, 0, 3, 4, 0, 0, 0…\n$ potential_issue   <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ pieces_past_due   <dbl> 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ perf_6_month_avg  <dbl> 0.90, 0.96, 0.81, 0.96, 0.98, 0.00, 1.00, 0.69, 1.00…\n$ perf_12_month_avg <dbl> 0.89, 0.97, 0.88, 0.98, 0.98, 0.00, 0.97, 0.68, 0.95…\n$ local_bo_qty      <dbl> 0, 0, 0, 0, 0, 0, 34, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, …\n$ deck_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ oe_constraint     <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ ppap_risk         <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"No\", \"No…\n$ stop_auto_buy     <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n$ rev_stop          <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\"…\n$ went_on_backorder <chr> \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Ye…\n```\n:::\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-3_6192f15682777d9684efa04956a8e897'}\n\n```{.r .cell-code}\nrecipe_obj <- recipe(went_on_backorder ~ ., data = product_backorders_tbl) %>%\n  step_zv(all_predictors()) %>%\n  step_mutate_at(potential_issue, deck_risk, oe_constraint, ppap_risk, stop_auto_buy, rev_stop, fn = as.factor) %>%\n  prep()\n```\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-4_f7fae172f71ed099aeee7e4602036e4b'}\n\n```{.r .cell-code}\nset.seed(1234)\n\nsplit_obj <- initial_split(product_backorders_tbl, prop = 0.85)\ntrain_readable_tbl <- training(split_obj)\ntest_readable_tbl <- testing(split_obj)\n\ntrain_tbl <- bake(recipe_obj, new_data = train_readable_tbl)\ntest_tbl  <- bake(recipe_obj, new_data = test_readable_tbl)\n```\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-5_eee0e07f2e27a72c6823b96250445a04'}\n\n```{.r .cell-code}\nh2o.init()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nH2O is not running yet, starting it now...\n\nNote:  In case of errors look at the following log files:\n    C:\\Users\\Lenovo\\AppData\\Local\\Temp\\RtmpYh8ymY\\file4d947cd86317/h2o_Lenovo_started_from_r.out\n    C:\\Users\\Lenovo\\AppData\\Local\\Temp\\RtmpYh8ymY\\file4d9460a46251/h2o_Lenovo_started_from_r.err\n\n\nStarting H2O JVM and connecting:  Connection successful!\n\nR is connected to the H2O cluster: \n    H2O cluster uptime:         2 seconds 452 milliseconds \n    H2O cluster timezone:       Europe/Berlin \n    H2O data parsing timezone:  UTC \n    H2O cluster version:        3.44.0.3 \n    H2O cluster version age:    6 months and 5 days \n    H2O cluster name:           H2O_started_from_R_Lenovo_pgz902 \n    H2O cluster total nodes:    1 \n    H2O cluster total memory:   1.74 GB \n    H2O cluster total cores:    8 \n    H2O cluster allowed cores:  8 \n    H2O cluster healthy:        TRUE \n    H2O Connection ip:          localhost \n    H2O Connection port:        54321 \n    H2O Connection proxy:       NA \n    H2O Internal Security:      FALSE \n    R Version:                  R version 4.3.0 (2023-04-21 ucrt) \n```\n:::\n\n```{.r .cell-code}\nsplit_h2o <- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.85), seed = 1234)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ntrain_h2o <- split_h2o[[1]]\nvalid_h2o <- split_h2o[[2]]\ntest_h2o  <- as.h2o(test_tbl)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\ny <- \"went_on_backorder\"\nx <- setdiff(names(train_h2o), y)\n```\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-6_0711d26c57bff4cd578cf9b1a5cce3cf'}\n\n```{.r .cell-code}\nautoml_models_h2o <- h2o.automl(\n  x = x,\n  y = y,\n  training_frame    = train_h2o,\n  validation_frame  = valid_h2o,\n  leaderboard_frame = test_h2o,\n  max_runtime_secs  = 120,\n  nfolds            = 5 \n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |=                                                                     |   1%\n23:27:05.701: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.\n23:27:05.719: AutoML: XGBoost is not available; skipping it.\n  |                                                                            \n  |==                                                                    |   3%\n  |                                                                            \n  |====                                                                  |   5%\n  |                                                                            \n  |=====                                                                 |   7%\n  |                                                                            \n  |=======                                                               |  10%\n  |                                                                            \n  |========                                                              |  11%\n  |                                                                            \n  |=========                                                             |  13%\n  |                                                                            \n  |==========                                                            |  15%\n  |                                                                            \n  |============                                                          |  17%\n  |                                                                            \n  |=============                                                         |  19%\n  |                                                                            \n  |===============                                                       |  21%\n  |                                                                            \n  |================                                                      |  23%\n  |                                                                            \n  |=================                                                     |  25%\n  |                                                                            \n  |==================                                                    |  26%\n  |                                                                            \n  |====================                                                  |  28%\n  |                                                                            \n  |=====================                                                 |  30%\n  |                                                                            \n  |=======================                                               |  32%\n  |                                                                            \n  |========================                                              |  34%\n  |                                                                            \n  |=========================                                             |  36%\n  |                                                                            \n  |==========================                                            |  38%\n  |                                                                            \n  |============================                                          |  39%\n  |                                                                            \n  |=============================                                         |  41%\n  |                                                                            \n  |==============================                                        |  44%\n  |                                                                            \n  |================================                                      |  45%\n  |                                                                            \n  |=================================                                     |  47%\n  |                                                                            \n  |==================================                                    |  49%\n  |                                                                            \n  |===================================                                   |  50%\n  |                                                                            \n  |=====================================                                 |  52%\n  |                                                                            \n  |======================================                                |  55%\n  |                                                                            \n  |========================================                              |  56%\n  |                                                                            \n  |=========================================                             |  59%\n  |                                                                            \n  |==========================================                            |  60%\n  |                                                                            \n  |===========================================                           |  62%\n  |                                                                            \n  |=============================================                         |  64%\n  |                                                                            \n  |==============================================                        |  66%\n  |                                                                            \n  |===============================================                       |  68%\n  |                                                                            \n  |================================================                      |  69%\n  |                                                                            \n  |==================================================                    |  71%\n  |                                                                            \n  |===================================================                   |  73%\n  |                                                                            \n  |====================================================                  |  75%\n  |                                                                            \n  |=====================================================                 |  76%\n  |                                                                            \n  |=======================================================               |  79%\n  |                                                                            \n  |=========================================================             |  81%\n  |                                                                            \n  |==========================================================            |  83%\n  |                                                                            \n  |============================================================          |  85%\n  |                                                                            \n  |=============================================================         |  87%\n  |                                                                            \n  |===============================================================       |  90%\n  |                                                                            \n  |================================================================      |  92%\n  |                                                                            \n  |==================================================================    |  94%\n  |                                                                            \n  |===================================================================   |  96%\n  |                                                                            \n  |====================================================================  |  97%\n  |                                                                            \n  |===================================================================== |  99%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-7_6e16b0a6a48409cb0f0daaca2824bdee'}\n\n```{.r .cell-code}\ntypeof(automl_models_h2o)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"S4\"\n```\n:::\n\n```{.r .cell-code}\nslotNames(automl_models_h2o)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"project_name\"   \"leader\"         \"leaderboard\"    \"event_log\"     \n[5] \"modeling_steps\" \"training_info\" \n```\n:::\n\n```{.r .cell-code}\nautoml_models_h2o@leaderboard\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                                                 model_id       auc   logloss\n1    StackedEnsemble_AllModels_3_AutoML_1_20240625_232705 0.9548733 0.1728805\n2    StackedEnsemble_AllModels_2_AutoML_1_20240625_232705 0.9547081 0.1727886\n3 StackedEnsemble_BestOfFamily_4_AutoML_1_20240625_232705 0.9540194 0.1735851\n4    StackedEnsemble_AllModels_1_AutoML_1_20240625_232705 0.9536971 0.1739514\n5 StackedEnsemble_BestOfFamily_3_AutoML_1_20240625_232705 0.9532465 0.1740056\n6 StackedEnsemble_BestOfFamily_2_AutoML_1_20240625_232705 0.9519997 0.1755682\n      aucpr mean_per_class_error      rmse        mse\n1 0.7604330            0.1382261 0.2289064 0.05239816\n2 0.7599018            0.1437114 0.2285484 0.05223435\n3 0.7593345            0.1402798 0.2293229 0.05258898\n4 0.7579727            0.1542829 0.2290666 0.05247150\n5 0.7559415            0.1583134 0.2298750 0.05284250\n6 0.7565212            0.1483599 0.2310066 0.05336406\n\n[29 rows x 7 columns] \n```\n:::\n\n```{.r .cell-code}\nautoml_models_h2o@leader\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel Details:\n==============\n\nH2OBinomialModel: stackedensemble\nModel ID:  StackedEnsemble_AllModels_3_AutoML_1_20240625_232705 \nModel Summary for Stacked Ensemble: \n                                         key            value\n1                          Stacking strategy cross_validation\n2       Number of base models (used / total)             9/22\n3           # GBM base models (used / total)             8/14\n4           # DRF base models (used / total)              1/2\n5  # DeepLearning base models (used / total)              0/5\n6           # GLM base models (used / total)              0/1\n7                      Metalearner algorithm              GLM\n8         Metalearner fold assignment scheme           Random\n9                         Metalearner nfolds                5\n10                   Metalearner fold_column               NA\n11        Custom metalearner hyperparameters             None\n\n\nH2OBinomialMetrics: stackedensemble\n** Reported on training data. **\n\nMSE:  0.02437821\nRMSE:  0.1561352\nLogLoss:  0.0933589\nMean Per-Class Error:  0.06967836\nAUC:  0.9906361\nAUCPR:  0.9460185\nGini:  0.9812722\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n         No  Yes    Error       Rate\nNo     8642  148 0.016837  =148/8790\nYes     142 1017 0.122519  =142/1159\nTotals 8784 1165 0.029149  =290/9949\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold       value idx\n1                       max f1  0.422552    0.875215 174\n2                       max f2  0.262859    0.893033 222\n3                 max f0point5  0.617980    0.903652 124\n4                 max accuracy  0.422552    0.970851 174\n5                max precision  0.991451    1.000000   0\n6                   max recall  0.031914    1.000000 338\n7              max specificity  0.991451    1.000000   0\n8             max absolute_mcc  0.422552    0.858717 174\n9   max min_per_class_accuracy  0.215653    0.948009 238\n10 max mean_per_class_accuracy  0.180647    0.949358 252\n11                     max tns  0.991451 8790.000000   0\n12                     max fns  0.991451 1157.000000   0\n13                     max fps  0.000416 8790.000000 399\n14                     max tps  0.031914 1159.000000 338\n15                     max tnr  0.991451    1.000000   0\n16                     max fnr  0.991451    0.998274   0\n17                     max fpr  0.000416    1.000000 399\n18                     max tpr  0.031914    1.000000 338\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: stackedensemble\n** Reported on validation data. **\n\nMSE:  0.04460969\nRMSE:  0.2112101\nLogLoss:  0.1505602\nMean Per-Class Error:  0.1424718\nAUC:  0.9603354\nAUCPR:  0.7811182\nGini:  0.9206708\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n         No Yes    Error       Rate\nNo     2032  97 0.045561   =97/2129\nYes      62 197 0.239382    =62/259\nTotals 2094 294 0.066583  =159/2388\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold       value idx\n1                       max f1  0.365780    0.712477 168\n2                       max f2  0.165055    0.795377 240\n3                 max f0point5  0.626247    0.752742 100\n4                 max accuracy  0.626247    0.940117 100\n5                max precision  0.973763    1.000000   0\n6                   max recall  0.014714    1.000000 360\n7              max specificity  0.973763    1.000000   0\n8             max absolute_mcc  0.271552    0.680105 199\n9   max min_per_class_accuracy  0.165055    0.903475 240\n10 max mean_per_class_accuracy  0.165055    0.904532 240\n11                     max tns  0.973763 2129.000000   0\n12                     max fns  0.973763  257.000000   0\n13                     max fps  0.000192 2129.000000 399\n14                     max tps  0.014714  259.000000 360\n15                     max tnr  0.973763    1.000000   0\n16                     max fnr  0.973763    0.992278   0\n17                     max fpr  0.000192    1.000000 399\n18                     max tpr  0.014714    1.000000 360\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nH2OBinomialMetrics: stackedensemble\n** Reported on cross-validation data. **\n** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **\n\nMSE:  0.05051532\nRMSE:  0.2247561\nLogLoss:  0.1712053\nMean Per-Class Error:  0.1406656\nAUC:  0.9512413\nAUCPR:  0.7488303\nGini:  0.9024825\n\nConfusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:\n          No  Yes    Error         Rate\nNo     11482  671 0.055213   =671/12153\nYes      374 1280 0.226119    =374/1654\nTotals 11856 1951 0.075686  =1045/13807\n\nMaximum Metrics: Maximum metrics at their respective thresholds\n                        metric threshold        value idx\n1                       max f1  0.294349     0.710125 219\n2                       max f2  0.099855     0.774582 298\n3                 max f0point5  0.580956     0.740056 132\n4                 max accuracy  0.520655     0.931991 150\n5                max precision  0.990710     1.000000   0\n6                   max recall  0.000569     1.000000 399\n7              max specificity  0.990710     1.000000   0\n8             max absolute_mcc  0.294349     0.669947 219\n9   max min_per_class_accuracy  0.115929     0.885127 289\n10 max mean_per_class_accuracy  0.099855     0.888368 298\n11                     max tns  0.990710 12153.000000   0\n12                     max fns  0.990710  1651.000000   0\n13                     max fps  0.000569 12153.000000 399\n14                     max tps  0.000569  1654.000000 399\n15                     max tnr  0.990710     1.000000   0\n16                     max fnr  0.990710     0.998186   0\n17                     max fpr  0.000569     1.000000 399\n18                     max tpr  0.000569     1.000000 399\n\nGains/Lift Table: Extract with `h2o.gainsLift(<model>, <data>)` or `h2o.gainsLift(<model>, valid=<T/F>, xval=<T/F>)`\nCross-Validation Metrics Summary: \n                mean        sd cv_1_valid cv_2_valid cv_3_valid cv_4_valid\naccuracy    0.928305  0.007256   0.939850   0.929517   0.924751   0.926934\nauc         0.951701  0.005000   0.952292   0.956566   0.956173   0.944906\nerr         0.071695  0.007256   0.060150   0.070483   0.075249   0.073066\nerr_count 197.800000 18.005554 168.000000 197.000000 204.000000 204.000000\nf0point5    0.697153  0.039922   0.760870   0.698782   0.697976   0.671902\n          cv_5_valid\naccuracy    0.920471\nauc         0.948565\nerr         0.079529\nerr_count 216.000000\nf0point5    0.656234\n\n---\n                        mean        sd cv_1_valid cv_2_valid cv_3_valid\nprecision           0.685291  0.057626   0.780405   0.680412   0.681013\nr2                  0.520771  0.022106   0.544114   0.538521   0.525494\nrecall              0.758704  0.046514   0.691617   0.783383   0.775216\nresidual_deviance 942.443100 17.285223 925.780700 923.117800 952.937300\nrmse                0.224672  0.004587   0.219083   0.221208   0.230133\nspecificity         0.951331  0.013934   0.973567   0.949553   0.946700\n                  cv_4_valid cv_5_valid\nprecision           0.658120   0.626506\nr2                  0.494483   0.501244\nrecall              0.733333   0.809969\nresidual_deviance 962.569760 947.809800\nrmse                0.224942   0.227992\nspecificity         0.951554   0.935282\n```\n:::\n\n```{.r .cell-code}\ntypeof(automl_models_h2o@leader)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"S4\"\n```\n:::\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-8_0b806c83667d38f763f024e084be3cd1'}\n\n```{.r .cell-code}\npredictions <- h2o.predict(automl_models_h2o@leader, newdata = as.h2o(test_tbl))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n\n  |                                                                            \n  |                                                                      |   0%\n  |                                                                            \n  |======================================================================| 100%\n```\n:::\n\n```{.r .cell-code}\npredictions_tbl <- \n  predictions %>% \n    as_tibble()\n#h2o.saveModel(automl_models_h2o@leader, path = \"./04_perf_meas_files/\")\n```\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-9_4b2c9b11aeeb663884dab9953ae2b7ce'}\n\n```{.r .cell-code}\npredictions_tbl %>%\n  glimpse()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 2,858\nColumns: 3\n$ predict <fct> Yes, Yes, Yes, Yes, Yes, Yes, No, No, Yes, Yes, Yes, Yes, No, …\n$ No      <dbl> 0.30736370, 0.50370304, 0.06602003, 0.16403161, 0.04737343, 0.…\n$ Yes     <dbl> 0.69263630, 0.49629696, 0.93397997, 0.83596839, 0.95262657, 0.…\n```\n:::\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-10_f192aa049491e9f2dcc826d0ef20b8ee'}\n\n```{.r .cell-code}\nautoml_models_h2o@leaderboard %>% \n              as_tibble() %>% \n              select(-c(mean_per_class_error, rmse, mse))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 29 × 4\n   model_id                                                  auc logloss aucpr\n   <chr>                                                   <dbl>   <dbl> <dbl>\n 1 StackedEnsemble_AllModels_3_AutoML_1_20240625_232705    0.955   0.173 0.760\n 2 StackedEnsemble_AllModels_2_AutoML_1_20240625_232705    0.955   0.173 0.760\n 3 StackedEnsemble_BestOfFamily_4_AutoML_1_20240625_232705 0.954   0.174 0.759\n 4 StackedEnsemble_AllModels_1_AutoML_1_20240625_232705    0.954   0.174 0.758\n 5 StackedEnsemble_BestOfFamily_3_AutoML_1_20240625_232705 0.953   0.174 0.756\n 6 StackedEnsemble_BestOfFamily_2_AutoML_1_20240625_232705 0.952   0.176 0.757\n 7 GBM_grid_1_AutoML_1_20240625_232705_model_3             0.952   0.178 0.750\n 8 StackedEnsemble_BestOfFamily_1_AutoML_1_20240625_232705 0.951   0.178 0.751\n 9 GBM_1_AutoML_1_20240625_232705                          0.950   0.179 0.750\n10 GBM_3_AutoML_1_20240625_232705                          0.950   0.181 0.750\n# ℹ 19 more rows\n```\n:::\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-11_e7bcf14327fa135c5f55a855b0e7d63f'}\n\n```{.r .cell-code}\nplot_h2o_leaderboard <- function(h2o_leaderboard, order_by = c(\"auc\", \"logloss\"), \n                                 n_max = 20, size = 4, include_lbl = TRUE) {\n\n    # Setup inputs\n    # adjust input so that all formats are working\n    order_by <- tolower(order_by[[1]])\n\n    leaderboard_tbl <- h2o_leaderboard %>%\n        as_tibble() %>%\n        select(-c(aucpr, mean_per_class_error, rmse, mse)) %>% \n        mutate(model_type = str_extract(model_id, \"[^_]+\")) %>%\n        rownames_to_column(var = \"rowname\") %>%\n        mutate(model_id = paste0(rowname, \". \", model_id) %>% as.factor())\n\n    # Transformation\n    if (order_by == \"auc\") {\n\n        data_transformed_tbl <- leaderboard_tbl %>%\n            slice(1:n_max) %>%\n            mutate(\n                model_id   = as_factor(model_id) %>% reorder(auc),\n                model_type = as.factor(model_type)\n            ) %>%\n                pivot_longer(cols = -c(model_id, model_type, rowname), \n                       names_to = \"key\", \n                       values_to = \"value\", \n                       names_transform = list(key = forcats::fct_inorder)\n                       )\n\n    } else if (order_by == \"logloss\") {\n\n        data_transformed_tbl <- leaderboard_tbl %>%\n            slice(1:n_max) %>%\n            mutate(\n                model_id   = as_factor(model_id) %>% reorder(logloss) %>% fct_rev(),\n                model_type = as.factor(model_type)\n            ) %>%\n            pivot_longer(cols = -c(model_id, model_type, rowname), \n                       names_to = \"key\", \n                       values_to = \"value\", \n                       names_transform = list(key = forcats::fct_inorder)\n                       )\n\n    } else {\n        # If nothing is supplied\n        stop(paste0(\"order_by = '\", order_by, \"' is not a permitted option.\"))\n    }\n\n    # Visualization\n    g <- data_transformed_tbl %>%\n        ggplot(aes(value, model_id, color = model_type)) +\n        geom_point(size = size) +\n        facet_wrap(~ key, scales = \"free_x\") +\n        labs(title = \"Leaderboard Metrics\",\n             subtitle = paste0(\"Ordered by: \", toupper(order_by)),\n             y = \"Model Postion, Model ID\", x = \"\")\n\n    if (include_lbl) g <- g + geom_label(aes(label = round(value, 2), \n                                             hjust = \"inward\"))\n\n    return(g)\n\n}\n```\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-12_3630dea32c1883d024222db1ede8476e'}\n\n```{.r .cell-code}\nautoml_models_h2o@leaderboard %>% plot_h2o_leaderboard()\n```\n\n::: {.cell-output-display}\n![](Chapter_3b-_and_4_Challenge_fahad_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\nI was unable to build the page because the program have some problem with an h2o function. So I saved the results and loaded them. The used code is commented out for a better understanding.\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-13_3607793476fd0f32091c2ee5897b309e'}\n\n```{.r .cell-code}\n#h2o.init()\n#deeplearning_h2o <- \n#h2o.loadModel(\"C:/Users/Lenovo/OneDrive/Desktop/daqtascience/ss24-bdml-Fahad221999/Business Decisions with Machine Learning/DeepLearning_1_AutoML_3_20220614_234925\")\n#deeplearning_h2o@allparameters\n\n#Deeplearning_grid_01 <- h2o.grid()\n \n#     # See help page for available algos\n    #algorithm = \"deeplearning\"\n#     \n#     # I just use the same as the object\n    #grid_id = \"Deaplearning_grid_01\"\n#     \n#     # The following is for ?h2o.deeplearning()\n#     # predictor and response variables\n     #x = x,\n     #y = y,\n#     \n#     # training and validation frame and crossfold validation\n#     training_frame   = train_h2o,\n#     validation_frame = valid_h2o,\n#     nfolds = 5,\n#     \n#     # Hyperparamters: Use deeplearning_h2o@allparameters to see all\n#     hyper_params = list(\n#         # Use some combinations (the first one was the original)\n#         hidden = list(c(10, 10, 10), c(50, 20, 10), c(20, 20, 20)),\n#         epochs = c(10, 50, 100)\n#     )\n# )\n```\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-14_2effd82a6aff49c3f46d3d6f0ed35e3e'}\n\n```{.r .cell-code}\n# <- h2o.getModel(\"Deaplearning_grid_01_model_3\")\n#Deeplearning_grid_01_model_3 %>%h2o.saveModel(path = \"04_Modeling/Deaplearning_grid_01_model_3\")\n#Deeplearning_grid_01_model_3 <- h2o.loadModel(\"04_Modeling/Deaplearning_grid_01_model_3/Deaplearning_grid_01_model_3\")\n# performance_h2o <- h2o.performance(Deeplearning_grid_01_model_3, newdata = as.h2o(test_tbl))\n# \n# performance_tbl <- performance_h2o %>%\n#     h2o.metric() %>%\n#     as.tibble()\n# \n# theme_new <- theme(\n#       legend.position  = \"bottom\",\n#       panel.background = element_rect(fill   = \"transparent\"),\n#       panel.border     = element_rect(color = \"black\", fill = NA, size = 0.5),\n#       panel.grid.major = element_line(color = \"grey\", size = 0.333)\n#       ) \n #saveRDS(performance_tbl, file = \"performance_tbl.rds\")\n\n#performance_tbl <- readRDS(\"performance_tbl.rds\")\n```\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-15_c5aa7432b7167077d6486ff6b41ffde8'}\n\n```{.r .cell-code}\n#performance_tbl %>%\n    #filter(f1 == max(f1))\n\n#performance_tbl %>%\n    #ggplot(aes(x = threshold)) +\n    #geom_line(aes(y = precision), color = \"blue\", size = 1) +\n    #geom_line(aes(y = recall), color = \"red\", size = 1) +\n    \n    # Insert line where precision and recall are harmonically optimized\n    #geom_vline(xintercept = h2o.find_threshold_by_max_metric(performance_h2o, \"f1\")) +\n    #labs(title = \"Precision vs Recall\", y = \"value\") +\n    #theme_new\nknitr::include_graphics(\"E:/Fahad/bdml-injolifi/04_perf_meas_files/figure-html/unnamed-chunk-15-1.png\")\n```\n\n::: {.cell-output-display}\n![](E:/Fahad/bdml-injolifi/04_perf_meas_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-16_fbbc1f01c53cbe43f549c76c508337cf'}\n\n```{.r .cell-code}\n#p1 <- performance_tbl %>%\n  #ggplot(aes(fpr, tpr)) +\n    #geom_line(size = 1) +\n    \n    # just for demonstration purposes\n    #geom_abline(color = \"red\", linetype = \"dotted\") +\n    \n    #theme_new +\n    #theme(\n      #legend.direction = \"vertical\",\n      #) +\n    #labs(\n        #title = \"ROC Plot\"\n        #subtitle = \"Performance of 3 Top Performing Models\"\n   # )\n#p1\nknitr::include_graphics(\"E:/Fahad/bdml-injolifi/04_perf_meas_files/figure-html/unnamed-chunk-16-1.png\")\n```\n\n::: {.cell-output-display}\n![](E:/Fahad/bdml-injolifi/04_perf_meas_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-17_6d24d9b12f83548be34ea3f11db3593b'}\n\n```{.r .cell-code}\n#p2 <- performance_tbl %>%\n  #ggplot(aes(recall, precision)) +\n    #geom_line(size = 1) +\n    #theme_new + \n    #theme(\n      #legend.direction = \"vertical\",\n      #) +\n    #labs(\n        #title = \"Precision vs Recall Plot\"\n        #subtitle = \"Performance of 3 Top Performing Models\"\n    #)\n#p2\nknitr::include_graphics(\"E:/Fahad/bdml-injolifi/04_perf_meas_files/figure-html/unnamed-chunk-17-1.png\")\n```\n\n::: {.cell-output-display}\n![](E:/Fahad/bdml-injolifi/04_perf_meas_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-18_39e9450d8ce5889d8d1996fbc58c22c7'}\n\n```{.r .cell-code}\nranked_predictions_tbl <- predictions_tbl %>%\n    bind_cols(test_tbl) %>%\n    select(predict:Yes, went_on_backorder) %>%\n    # Sorting from highest to lowest class probability\n    arrange(desc(Yes))\n\ncalculated_gain_lift_tbl <- ranked_predictions_tbl %>%\n    mutate(ntile = ntile(Yes, n = 10)) %>%\n    group_by(ntile) %>%\n    summarise(\n        cases = n(),\n        responses = sum(went_on_backorder == \"Yes\")\n    ) %>%\n    arrange(desc(ntile)) %>%\n    \n    # Add group numbers (opposite of ntile)\n    mutate(group = row_number()) %>%\n    select(group, cases, responses) %>%\n    \n    # Calculations\n    mutate(\n        cumulative_responses = cumsum(responses),\n        pct_responses        = responses / sum(responses),\n        gain                 = cumsum(pct_responses),\n        cumulative_pct_cases = cumsum(cases) / sum(cases),\n        lift                 = gain / cumulative_pct_cases,\n        gain_baseline        = cumulative_pct_cases,\n        lift_baseline        = gain_baseline / cumulative_pct_cases\n    )\n```\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-19_15126cb9d7c59815119cbda0d3fba97d'}\n\n```{.r .cell-code}\n#gain_lift_tbl <- performance_h2o %>%\n    #h2o.gainsLift() %>%\n    #as.tibble()\n\n#gain_transformed_tbl <- gain_lift_tbl %>% \n    #select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n    #select(-contains(\"lift\")) %>%\n    #mutate(baseline = cumulative_data_fraction) %>%\n    #rename(gain     = cumulative_capture_rate) %>%\n    # prepare the data for the plotting (for the color and group aesthetics)\n    #pivot_longer(cols = c(gain, baseline), values_to = \"value\", names_to = \"key\")\n\n#p3 <- gain_transformed_tbl %>%\n    #ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n    #geom_line(size = 1.5) +\n    #labs(\n        #title = \"Gain Chart\",\n        #x = \"Cumulative Data Fraction\",\n        #y = \"Gain\"\n    #) +\n    #theme_new\n#p3\nknitr::include_graphics(\"E:/Fahad/bdml-injolifi/04_perf_meas_files/figure-html/unnamed-chunk-19-1.png\")\n```\n\n::: {.cell-output-display}\n![](E:/Fahad/bdml-injolifi/04_perf_meas_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-20_b5e584926d06f89442a33cd03c94041c'}\n\n```{.r .cell-code}\n#lift_transformed_tbl <- gain_lift_tbl %>% \n#    select(group, cumulative_data_fraction, cumulative_capture_rate, cumulative_lift) %>%\n#    select(-contains(\"capture\")) %>%\n#    mutate(baseline = 1) %>%\n#    rename(lift = cumulative_lift) %>%\n#    pivot_longer(cols = c(lift, baseline), values_to = \"value\", names_to = \"key\")\n#\n#p4 <- lift_transformed_tbl %>%\n#    ggplot(aes(x = cumulative_data_fraction, y = value, color = key)) +\n#    geom_line(size = 1.5) +\n#    labs(\n#        title = \"Lift Chart\",\n#        x = \"Cumulative Data Fraction\",\n#        y = \"Lift\"\n#    ) +\n#    theme_new\n#p4\nknitr::include_graphics(\"E:/Fahad/bdml-injolifi/04_perf_meas_files/figure-html/unnamed-chunk-20-1.png\")\n```\n\n::: {.cell-output-display}\n![](E:/Fahad/bdml-injolifi/04_perf_meas_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-21_5f59413fe6d429871a5c7fa6fe93d3bf'}\n\n```{.r .cell-code}\nlibrary(cowplot)\nlibrary(glue)\n```\n:::\n\n::: {.cell hash='Chapter_3b-_and_4_Challenge_fahad_cache/html/unnamed-chunk-22_c758a7cfbf3c92df334cc0cbb17be718'}\n\n```{.r .cell-code}\n# Combine using cowplot\n   # \n#    # cowplot::get_legend extracts a legend from a ggplot object\n  #  p_legend <- get_legend(p1)\n#    # Remove legend from p1\n #   p1 <- p1 + theme(legend.position = \"none\")\n    \n    # cowplot::plt_grid() combines multiple ggplots into a single cowplot object\n#    p <- cowplot::plot_grid(p1, p2, p3, p4, ncol = 2)\n #   p\nknitr::include_graphics(\"E:/Fahad/bdml-injolifi/04_perf_meas_files/figure-html/unnamed-chunk-21-1.png\")\n```\n\n::: {.cell-output-display}\n![](E:/Fahad/bdml-injolifi/04_perf_meas_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}